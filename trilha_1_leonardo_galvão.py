# -*- coding: utf-8 -*-
"""Trilha_1_Leonardo Galvão.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1twc1HieUqs46RzSTDUpO-wFh7kXuqA1x

"A frequência de palavras e letras em corpos de texto tem sido bastante estudada para diversos propósitos, sendo um deles a criptografia."

**Lei de Zipf**
Trata-se de uma lei de potências sobre a distribuição de valores de acordo com o nº de ordem numa lista. Numa lista, o membro n teria uma relação de valor com o 1º da lista segundo 1/n. Por exemplo, numa língua a frequência com que surgem as diversas palavras segue uma distribuição que se pode aproximar por:

## Pn ~ 1/n^a

onde Pn representa a frequência de uma palavra ordenada na n-ésima posição e o expoente a é próximo da unidade. Isto significa que o segundo elemento se repetirá aproximadamente com uma frequência que é metade da do primeiro, e o terceiro elemento com uma frequência de 1/3 e assim sucessivamente.

O objetivo desta atividade é demonstrar a **Lei de Zipf** através de um conjunto de dados obtidos através de textos na internet.
"""

#Acessando o wikipedia 
!pip install wikipedia 

from IPython import display
from IPython.display import clear_output
clear_output()

# Selecionando a pagina do Wikipedia.
# Importação do pacote wikipedia
import wikipedia

# Selecionando a pagina no winkipedia.

text = wikipedia.page('Breaking Bad', auto_suggest=False).section('Critical reception')

#Tamanho do texto em quantidade de palavras.
len(text)

#Exibindo o texto.
text

# retirando pontuações e caracteres especiais.
import re

text_clean = (
re.sub(pattern ="[^\w\s]",
       repl = "",
       string = text))
#Exbindo o texto.
text_clean

# Importando nltk corpus uma biblioteca que permite a utilização de stop words.
import nltk.corpus

#importando a função word_tokenize, esta é uma função em Python que divide uma determinada frase em palavras usando a biblioteca NLTK.
import nltk
from nltk.tokenize import word_tokenize

import nltk
nltk.download('punkt')

# Separando o texto em palavras.
List_tokens = word_tokenize(text_clean)

# Criando uma lista de palabras.
for word in enumerate(List_tokens):
  print(word)

#Importanto a função stopwords
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

#Verificando quais stop words existem no idioma do texto.
stop_words = stopwords.words('english')
print(stop_words)

# Criando uma nova lista
# Prenchendo a nova lista, retirando stopwords da lista texto.
texto = [w for w in text_clean if not w.lower() in stop_words]
texto = []

# Adicionando palavras da list_tokes para na lista texto, não sendo stop words.
for w in List_tokens:
    if w not in stop_words:
        texto.append(w)

# TRansformando a lista para minusculo.
for i in range(len(texto)):
    texto[i] = texto[i].lower()

print(texto)

from numpy.lib.function_base import delete
#criando um dicionario atráves de um contador de palavras na lista texto.
from collections import Counter
count_word = Counter(texto)
print(count_word)

# Importanto bilioteca para plot de graficos.
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt


df = pd.DataFrame(count_word.items(),  columns=['word', 'count']).sort_values('count',ascending=False)
df = df[df['count'] > 1] # somente termos com mais de 1 ocorrências


plt.figure(figsize=(10,24))
sns.set(style="darkgrid")
#mpl.style.use(['seaborn'])
sns.barplot(x=df['count'],y=df.word,color='#69b3a2')
plt.xticks(rotation=90) 
# Add title
plt.title('Words ranking by Critical reception Breaking bad Series');

plt.show()

#Transformando dicionanrio em STRING
sr = str(count_word)
print(type(sr))
print(f"Converted string: {sr}")

#Criando Wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Create lsita de palabras
texto_cloud_word = count_word 

# Create the wordcloud object
wordcloud = WordCloud(width=600, height=1000, margin=0).generate(sr)

# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.margins(x=0, y=0)
plt.show()

"""**Conclusão:**
Podemos observar lei de Zipf de fato funciona avaliando as frequências de palavras para levar a boas pistas sobre o conteúdo geral do texto. É claro que ela é uma aproximação, pois a linguística é uma ciência humana, sujeita a flutuações. Mas é uma aproximação bastante segura, e uma prova uma prova curiosa de que, diferenças culturais à parte, há laços fortes unindo todas as línguas.

"""